{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import gensim\n",
    "\n",
    "#either use google's word2vec or use your own trained model and check which one is working better for you.\n",
    "\n",
    "#Choose from one of the below models\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# model = Word2Vec.load('word2vec_model.pkl')\n",
    "\n",
    "with open('processed_comments', 'rb') as f:\n",
    "     clean_comments = pickle.load(f)\n",
    "        \n",
    "with open('unprocessed_comments', 'rb') as f:\n",
    "     unclean_comments = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clean_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tfidf scores computation\n",
    "\n",
    "n = len(clean_comments)\n",
    "start_index = len(clean_comments)-n\n",
    "clean_comments = clean_comments[start_index:len(clean_comments)]\n",
    "unclean_comments = unclean_comments[start_index:len(unclean_comments)]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf  = TfidfVectorizer(use_idf=True)\n",
    "tfidf_data = []\n",
    "for i in range(len(clean_comments)):\n",
    "    temp_vec = []\n",
    "    for j in range(len(clean_comments[i])):\n",
    "        temp_vec.append(str(clean_comments[i][j]))\n",
    "    tfidf_data.append(' '.join(temp_vec))\n",
    "    \n",
    "tfidf_scores = tfidf.fit_transform(tfidf_data)\n",
    "tfidf.get_feature_names()\n",
    "vocab = tfidf.vocabulary_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top n words from text\n",
    "# This cell is optional to use as this induces biasing for the clusters. Use this if you know your domain specific \n",
    "# keywords and want them to be clearly separated from the rest of the clusters. Run this but assign the weights to the\n",
    "# first if in the next cell \n",
    "\n",
    "representational_vectors = []\n",
    "words = []\n",
    "\n",
    "#change this as per your domain and customer pain points. These keywords are just assumptions.\n",
    "words_vec = ['resolution', 'case', 'dispute', 'claim', 'receive', 'seller', 'buyer', 'refund', 'account', 'send', 'item', 'email', 'resolve', 'contact', \n",
    "        'close', 'open', 'transaction', 'message', 'claim', 'issue', 'problem', 'payment', 'phone', 'ship', 'find', 'view', 'credit', 'card', \n",
    "        'track', 'ebay', 'bank', 'center', 'show', 'report', 'address', 'hold', 'limitation', 'file', 'answer', 'deliver', 'website', 'email', 'respond', 'process', \n",
    "        'complaint', 'review', 'click', 'tab', 'navigation', 'spin', 'reload', 'image', 'evidence', 'scam', 'fraud', 'allow', \n",
    "        'unable', 'info', 'header', 'scroll', 'page', 'link', 'system', 'reason', 'access', 'see', 'unauthorized', 'cancel', 'chargeback', 'fix', 'proof', 'confirm', 'online', 'experience', \n",
    "        'pending', 'dashboard', 'restore', 'status', 'describe', 'confuse', 'appear', 'feedback', 'upload', 'load', 'refresh', 'communication', \n",
    "        'gmail', 'button', 'text', 'protection', 'steal', 'debit', 'record', 'enter', 'input', 'submit', 'invoice', 'password', 'security', 'statement', 'withdraw', \n",
    "        'fault', 'touch', 'app', 'browser', 'chrome', 'android', 'mobile', 'impossible', 'computer', 'screen', 'form', 'automate', 'delete', 'remove', 'advise', \n",
    "        'notification', 'multiple', 'raise', 'chat', 'report', 'create', 'easier', 'human', 'appeal', 'circle', 'visa', 'policy','reopen', 'attach', 'quick', 'select', 'method', 'subscription', \n",
    "        'automatic', 'authorize', 'documentation', 'prompt', 'query', 'decline', 'progress', 'estimate', 'download', 'exchange', 'service', 'faster', 'freeze', \n",
    "         'connect', 'error', 'wrong', 'permission', 'escalate', 'disappear', 'inconvenience', 'chargeback', 'duplicate', 'alert', 'initiate', 'design', 'wallet', 'directions' ]\n",
    "\n",
    "for i in range(len(words_vec)):\n",
    "    words.append(words_vec[i])\n",
    "\n",
    "final_words_dict = {}\n",
    "final_words = []\n",
    "count = 0\n",
    "for word in words:\n",
    "    if ((str(word) in final_words_dict) == False):\n",
    "        final_words_dict[str(word)] = count\n",
    "        count = count + 1\n",
    "        final_words.append(str(word))\n",
    "        word2vec_words = model.wv.most_similar (str(word),topn=5)\n",
    "        for i in range(len(word2vec_words)):\n",
    "            item = word2vec_words[i][0]\n",
    "            if (item in final_words_dict)== False:\n",
    "                final_words.append(item)\n",
    "                final_words_dict[item] = count\n",
    "                count = count + 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment_vectors simplified\n",
    "\n",
    "def rms(sentence_vector):\n",
    "    square_sum = 0;\n",
    "    for i in range(len(sentence_vector)):\n",
    "        square_sum = square_sum + (sentence_vector[i]*sentence_vector[i])\n",
    "    rms_value = math.sqrt(square_sum/len(sentence_vector))\n",
    "    rms_vector = sentence_vector\n",
    "    for i in range(len(sentence_vector)):\n",
    "        rms_vector[i] = sentence_vector[i]/rms_value\n",
    "    return rms_vector\n",
    "\n",
    "comment_vectors = []\n",
    "total_empty = 0\n",
    "for i in range(len(clean_comments)):\n",
    "    count = 0\n",
    "    word_vector = model.wv[clean_comments[0][0]] - model.wv[clean_comments[0][0]]\n",
    "    for j in range(len(clean_comments[i])):\n",
    "        if((str(clean_comments[i][j]) in final_words_dict) == True ):\n",
    "            count = count + 1\n",
    "            #Assign weight i.e multiply weight by a factor (10-20) if you used above cell\n",
    "            weight = model.wv[str(clean_comments[i][j])]*tfidf_scores[(i,vocab[clean_comments[i][j]])] * 30\n",
    "            word_vector = word_vector + weight\n",
    "        elif((str(clean_comments[i][j]) in model.wv.vocab) == True):\n",
    "            weight = model.wv[str(clean_comments[i][j])]*tfidf_scores[(i,vocab[clean_comments[i][j]])]\n",
    "            word_vector = word_vector + weight\n",
    "        else:\n",
    "            weight = tfidf_scores[(i,vocab[clean_comments[i][j]])]\n",
    "            word_vector = word_vector + weight\n",
    "            \n",
    "    rms_vector = rms(word_vector)\n",
    "    comment_vectors.append(rms_vector)\n",
    "    if(count == 0):\n",
    "        total_empty = total_empty + 1\n",
    "        \n",
    "print total_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comment_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the comments in 2-D plane using TSNE Algorithm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "RS = 20150101\n",
    "vectors_tsne = TSNE(random_state=RS).fit_transform(comment_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20, 20))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter(vectors_tsne[:,0], vectors_tsne[:,1], lw=0, s=40)\n",
    "ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments_vectors', 'wb') as f:\n",
    "    pickle.dump(comment_vectors, f)\n",
    "\n",
    "with open('vectors_tsne', 'wb') as f:\n",
    "    pickle.dump(vectors_tsne, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments_vectors', 'rb') as f:\n",
    "     comment_vectors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing statistics for feedbacks \n",
    "\n",
    "rating_data = pd.read_csv('Landing_page_feedbacks.csv')\n",
    "rating_data = rating_data['Overall Rating']\n",
    "token_count = np.array([ len(comment) for comment in clean_comments])\n",
    "token_count = token_count[-25660:]\n",
    "total_rating = 0\n",
    "for i in range(len(rating_data)):\n",
    "    total_rating = total_rating + float(rating_data[i])\n",
    "\n",
    "print \"Avg words per feedback:\", np.mean(token_count)\n",
    "print \"Std Deviation of feedbacks:\", np.std(token_count)\n",
    "print \"Length of max feedback:\", np.max(token_count)\n",
    "print \"Length of min feedback:\", np.min(token_count)\n",
    "print \"Avg Rating for 2017-2018:\", total_rating/len(rating_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking which number of clusters to choose\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "range_n_clusters = [5, 7, 9, 10, 15, 20, 25, 30, 35, 40, 50, 60]\n",
    "train_vectors = comment_vectors\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(train_vectors)\n",
    "    print(cluster_labels)\n",
    "    silhouette_avg = silhouette_score(train_vectors, cluster_labels, metric=\"cosine\")\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose your cluster number based on silhouette score and the plotted data points.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "# Set number of clusters you want\n",
    "n_clusters = 40\n",
    "train_vectors = comment_vectors\n",
    "\n",
    "clusterer = KMeans(n_clusters=n_clusters, random_state=35)\n",
    "cluster_labels = clusterer.fit_predict(train_vectors)\n",
    "silhouette_avg = silhouette_score(train_vectors, cluster_labels, metric='cosine')\n",
    "print(\"For n_clusters =\", n_clusters,\"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = []\n",
    "clean_clusters = []\n",
    "actual_comments = unclean_comments\n",
    "actual_clean_comments = clean_comments\n",
    "for i in range(n_clusters):\n",
    "    clusters.append([])\n",
    "    clean_clusters.append([])\n",
    "\n",
    "for i in range(len(cluster_labels)):\n",
    "    label = cluster_labels[i];\n",
    "    clusters[label].append(actual_comments[i])\n",
    "    clean_clusters[label].append(actual_clean_comments[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20, 20))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter(vectors_tsne[:,0], vectors_tsne[:,1], lw=0, s=40, c=cluster_labels, cmap = 'prism')\n",
    "\n",
    "ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comments_vectors', 'wb') as f:\n",
    "    pickle.dump(comment_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization of Clusters.\n",
    "\n",
    "from summa import summarizer\n",
    "\n",
    "data_for_summary = []\n",
    "    \n",
    "# print(' '.join(clean_clusters[5][0]))\n",
    "for i in range(len(clean_clusters)):\n",
    "    temp_data = []\n",
    "    for j in range(len(clean_clusters[i])):\n",
    "        text = ' '.join((clean_clusters[i][j]))\n",
    "        temp_data.append(text)\n",
    "    data_for_summary.append(temp_data)\n",
    "    \n",
    "for i in range(len(clean_clusters)):\n",
    "    temp_string =''\n",
    "    for j in range(len(data_for_summary[i])):\n",
    "        temp_string = temp_string + str(data_for_summary[i][j]) + '. '\n",
    "    data_for_summary[i] = temp_string\n",
    "\n",
    "#Set number of words you want in the summary of the cluster\n",
    "words_in_summary = 100\n",
    "summary_clusters = []\n",
    "for i in range(len(data_for_summary)):\n",
    "    summary_clusters.append(summarizer.summarize(data_for_summary[i], words = words_in_summary))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty printing of clusters with summaries and count of feedbacks in cluster and the avg rating for that cluster\n",
    "\n",
    "temp = np.zeros((len(clean_clusters),2)).astype(int)\n",
    "for i in range(len(clean_clusters)):\n",
    "    temp[i][0] = len(clean_clusters[i])\n",
    "    temp[i][1] = i\n",
    "\n",
    "temp = temp[np.argsort(-temp[:, 0])]\n",
    "\n",
    "def compute_avg_rating(cluster_number):\n",
    "    total = 0;\n",
    "    for i in range(len(clusters[cluster_number])):\n",
    "        total = total + float((clusters[cluster_number])[i][1])\n",
    "    return total/len(clusters[cluster_number])\n",
    "\n",
    "for i in range(len(temp)):\n",
    "    print \"Cluster\", temp[i][1],\":\", temp[i][0], \"  Avg. Rating:\", float(\"{0:.2f}\".format(compute_avg_rating(temp[i][1])))\n",
    "    print(summary_clusters[temp[i][1]])\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the full content of the clusters. Cluster numbers start from 0. These clusters are printed\n",
    "# in reverse chronological order\n",
    "\n",
    "# Set cluster_num to view it\n",
    "cluster_num = 23\n",
    "clusters[cluster_num][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script searches for the specific keywords in the whole corpus. You can provide the keywords you want to find.\n",
    "# Returns the feedbacks having all the keywords.\n",
    "\n",
    "import string\n",
    "\n",
    "def fetch_caseid_feedbacks(search):\n",
    "    resultant_cluster = []\n",
    "    keys = search.split()\n",
    "    keys_dict = {}\n",
    "    for i in range(len(keys)):\n",
    "        if( keys[i] not in keys_dict):\n",
    "            keys_dict[keys[i]] = i\n",
    "        \n",
    "    for i in range(len(unclean_comments)):\n",
    "        feedback_tokens = unclean_comments[i][0].split()\n",
    "        count = 0\n",
    "        comment_dict = {}\n",
    "        for j in range(len(feedback_tokens)):\n",
    "            if(str(feedback_tokens[j]) not in comment_dict):\n",
    "                    comment_dict[feedback_tokens[j]] = j\n",
    "        for key in keys_dict:\n",
    "            if key not in comment_dict:\n",
    "                count = count + 1\n",
    "                break\n",
    "        if count == 0:\n",
    "            resultant_cluster.append(unclean_comments[i])\n",
    "    return resultant_cluster\n",
    "\n",
    "keywords =  'your keywords separated by spaces'\n",
    "fetch_caseid_feedbacks(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the top n topics from clusters \n",
    "\n",
    "def cluster_topics(clean_clusters, len_of_topics, topics_per_cluster, words_in_each_topic):\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.decomposition import LatentDirichletAllocation\n",
    "    \n",
    "    topics_for_all = []\n",
    "    for i in range(len(clean_clusters)):\n",
    "        cluster_data = clean_clusters[i]\n",
    "        content = []\n",
    "        for i in range(len(cluster_data)):\n",
    "            content.append(str(' '.join(cluster_data[i])))\n",
    "\n",
    "        vectorizer = CountVectorizer(ngram_range = (len_of_topics, len_of_topics))\n",
    "        vect = vectorizer.fit_transform(content)\n",
    "        lda = LatentDirichletAllocation(n_components = topics_per_cluster)\n",
    "        topics = lda.fit_transform(vect)\n",
    "        sorting = np.argsort(lda.components_)[:,::-1]\n",
    "        features = np.array(vectorizer.get_feature_names())\n",
    "        \n",
    "        topics_for_all.append([topics_per_cluster,features,\n",
    "                               sorting, 1, words_in_each_topic])\n",
    "    return topics_for_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Arguments for cluster_topics ---> First = clean_clusters, second = len_of_topics, third = num of topics per cluster\n",
    "topics_for_all = cluster_topics(clean_clusters, 3, 3, 3)\n",
    "def pretty_printing_topics(topics_for_all, cluster_number):\n",
    "    import mglearn\n",
    "    mglearn.tools.print_topics(topics=range(topics_for_all[cluster_number][0]), feature_names=topics_for_all[cluster_number][1],\n",
    "                                  sorting=topics_for_all[cluster_number][2], topics_per_chunk = topics_for_all[cluster_number][3], n_words = topics_for_all[cluster_number][4])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster for which you want the top n topics\n",
    "\n",
    "clust_num = 11\n",
    "pretty_printing_topics(topics_for_all, clust_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
